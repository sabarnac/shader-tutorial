"use strict";(self.webpackChunkshader_tutorial=self.webpackChunkshader_tutorial||[]).push([[78],{2368:function(e,t,r){r.r(t),r.d(t,{default:function(){return N}});var n=r(4794),a=r(2532),o=r(6540),i=r(9460),l=r(7154),c=r(6042),s=(r(6449),r(3514),r(7684)),u=r(6018),h=r(3461),m=r(6417),f=r(782),d="attribute vec4 vertexPosition;\nattribute vec2 vertexUv;\n\nuniform mat4 mvpMatrix;\n\nvarying highp vec2 uv;\n\nvoid main() {\n  gl_Position = mvpMatrix * vertexPosition;\n  uv = vertexUv;\n}";const p=d,v="varying highp vec2 uv;\n\nuniform sampler2D colorTextureSampler;\n\nvoid main() {\n  gl_FragColor = texture2D(colorTextureSampler, uv);\n}",x={vertex:{attributeLocations:{vertexPosition:"vec4",vertexUv:"vec2"},uniformLocations:{mvpMatrix:"mat4"}},fragment:{attributeLocations:{},uniformLocations:{colorTextureSampler:"sampler2D"}}},g=s.vt(),E=[[0,0],[0,1],[1,0],[0,1],[1,0],[1,1]];var b=(0,m.A)((()=>{const e={vertices:[[-1,-1,1],[-1,1,1],[1,-1,1],[-1,1,1],[1,-1,1],[1,1,1],[-1,-1,-1],[-1,1,-1],[-1,-1,1],[-1,1,-1],[-1,-1,1],[-1,1,1],[1,-1,1],[1,1,1],[1,-1,-1],[1,1,1],[1,-1,-1],[1,1,-1],[-1,1,1],[-1,1,-1],[1,1,1],[-1,1,-1],[1,1,1],[1,1,-1],[-1,-1,-1],[-1,-1,1],[1,-1,-1],[-1,-1,1],[1,-1,-1],[1,-1,1],[1,-1,-1],[1,1,-1],[-1,-1,-1],[1,1,-1],[-1,-1,-1],[-1,1,-1]],uvs:[].concat(E,E,E,E,E,E),indices:[[0,1,2,3,4,5],[6,7,8,9,10,11],[12,13,14,15,16,17],[18,19,20,21,22,23],[24,25,26,27,28,29],[30,31,32,33,34,35]],texture:u.A},{0:t,1:r}=(0,o.useState)(null),{0:n,1:a}=(0,o.useState)(null),{0:i,1:l}=(0,o.useState)(null),{0:c,1:m}=(0,o.useState)({vertices:null,uvs:null,indices:null,texture:null}),d=(0,o.useRef)();return(0,o.useEffect)((()=>{if(null!==d.current){const e=new f.A(d.current,g);return r(e),()=>{r(null),e.destroy()}}}),[d]),(0,o.useEffect)((0,h.sT)(null!==t,(()=>{a(t.createShaderProgram(p,v))})),[t]),(0,o.useEffect)((0,h.sT)(null!==n,(()=>{l(t.getDataLocations(n,x))})),[n]),(0,o.useEffect)((0,h.sT)(null!==i,(()=>{m({vertices:t.createStaticDrawArrayBuffer(e.vertices.flat(),c.vertices),uvs:t.createStaticDrawArrayBuffer(e.uvs.flat(),c.uvs),indices:t.createElementArrayBuffer(e.indices.flat(),c.indices),texture:t.createImageTexture(e.texture,c.texture)})})),[i]),(0,o.useEffect)((0,h.sT)(null!==c.vertices,(()=>{let r=!0;const a=()=>{t.renderScene((t=>{let{gl:o,projectionMatrix:l,viewMatrix:u,modelMatrix:h}=t;if(!r)return;const m=parseInt("undefined"!=typeof performance?performance.now():(0).toString()),f=s.vt(),d=m/30%2160*Math.PI/180;s.Qr(f,h,d),s.eL(f,f,d/2),s.Z8(f,f,d/3);const p=s.vt();s.lw(p,u,f),s.lw(p,l,p),o.bindBuffer(o.ARRAY_BUFFER,c.vertices),o.vertexAttribPointer(i.vertex.attributeLocations.vertexPosition,3,o.FLOAT,!1,0,0),o.enableVertexAttribArray(i.vertex.attributeLocations.vertexPosition),o.bindBuffer(o.ARRAY_BUFFER,c.uvs),o.vertexAttribPointer(i.vertex.attributeLocations.vertexUv,2,o.FLOAT,!1,0,0),o.enableVertexAttribArray(i.vertex.attributeLocations.vertexUv),o.bindBuffer(o.ELEMENT_ARRAY_BUFFER,c.indices),o.useProgram(n),o.uniformMatrix4fv(i.vertex.uniformLocations.mvpMatrix,!1,p),o.activeTexture(o.TEXTURE0),o.bindTexture(o.TEXTURE_2D,c.texture),o.uniform1i(i.fragment.uniformLocations.colorTextureSampler,0),o.drawElements(o.TRIANGLES,e.indices.length*e.indices[0].length,o.UNSIGNED_SHORT,0),requestAnimationFrame(a)}))};return requestAnimationFrame(a),()=>{r=!1}})),[c]),o.createElement("div",{className:"util text-center",style:{padding:"1rem"}},o.createElement("canvas",{width:"640",height:"480",ref:d},"Cannot run WebGL examples (not supported)"),o.createElement("pre",{className:"util text-left"},("\nCube:\n    Vertices:\n        Vertex 1: "+(0,h.NW)(e.vertices[0])+"\n        Vertex 2: "+(0,h.NW)(e.vertices[1])+"\n        Vertex 3: "+(0,h.NW)(e.vertices[2])+"\n        Vertex 4: "+(0,h.NW)(e.vertices[5])+"\n        Vertex 5: "+(0,h.NW)(e.vertices[30])+"\n        Vertex 6: "+(0,h.NW)(e.vertices[31])+"\n        Vertex 7: "+(0,h.NW)(e.vertices[32])+"\n        Vertex 8: "+(0,h.NW)(e.vertices[35])+"\n    Face UV:\n        Vertex 1: "+(0,h.nr)(E[0])+"\n        Vertex 2: "+(0,h.nr)(E[1])+"\n        Vertex 3: "+(0,h.nr)(E[2])+"\n        Vertex 4: "+(0,h.nr)(E[3])+"\n").trim()))}));const w=d,A="varying highp vec2 uv;\n\nuniform highp float time;\nuniform sampler2D colorTextureSampler;\n\nhighp float getColorShiftFactor(highp vec3 color) {\n  return clamp(ceil(3.0 - (color.r + color.g + color.b)), 0.0, 1.0);\n}\n\nvoid main() {\n  highp float colorShift = cos(time / 500.0);\n  highp vec4 textureColor = texture2D(colorTextureSampler, uv);\n  highp float finalColorShift = getColorShiftFactor(textureColor.rgb) * colorShift;\n  gl_FragColor = vec4(clamp(textureColor.rgb - finalColorShift, 0.0, 1.0), textureColor.a);\n}",y={vertex:{attributeLocations:{vertexPosition:"vec4",vertexUv:"vec2"},uniformLocations:{mvpMatrix:"mat4"}},fragment:{attributeLocations:{},uniformLocations:{time:"float",colorTextureSampler:"sampler2D"}}},S=s.vt(),T=[[0,0],[0,1],[1,0],[0,1],[1,0],[1,1]];var L=(0,m.A)((()=>{const e={vertices:[[-1,-1,1],[-1,1,1],[1,-1,1],[-1,1,1],[1,-1,1],[1,1,1],[-1,-1,-1],[-1,1,-1],[-1,-1,1],[-1,1,-1],[-1,-1,1],[-1,1,1],[1,-1,1],[1,1,1],[1,-1,-1],[1,1,1],[1,-1,-1],[1,1,-1],[-1,1,1],[-1,1,-1],[1,1,1],[-1,1,-1],[1,1,1],[1,1,-1],[-1,-1,-1],[-1,-1,1],[1,-1,-1],[-1,-1,1],[1,-1,-1],[1,-1,1],[1,-1,-1],[1,1,-1],[-1,-1,-1],[1,1,-1],[-1,-1,-1],[-1,1,-1]],uvs:[].concat(T,T,T,T,T,T),indices:[[0,1,2,3,4,5],[6,7,8,9,10,11],[12,13,14,15,16,17],[18,19,20,21,22,23],[24,25,26,27,28,29],[30,31,32,33,34,35]],texture:u.A},{0:t,1:r}=(0,o.useState)(null),{0:n,1:a}=(0,o.useState)(null),{0:i,1:l}=(0,o.useState)(null),{0:c,1:m}=(0,o.useState)({vertices:null,uvs:null,indices:null,texture:null}),{0:d,1:p}=(0,o.useState)("undefined"!=typeof performance?performance.now():0),v=(0,o.useRef)();return(0,o.useEffect)((()=>{if(null!==v.current){const e=new f.A(v.current,S);return r(e),()=>{r(null),e.destroy()}}}),[v]),(0,o.useEffect)((0,h.sT)(null!==t,(()=>{a(t.createShaderProgram(w,A))})),[t]),(0,o.useEffect)((0,h.sT)(null!==n,(()=>{l(t.getDataLocations(n,y))})),[n]),(0,o.useEffect)((0,h.sT)(null!==i,(()=>{m({vertices:t.createStaticDrawArrayBuffer(e.vertices.flat(),c.vertices),uvs:t.createStaticDrawArrayBuffer(e.uvs.flat(),c.uvs),indices:t.createElementArrayBuffer(e.indices.flat(),c.indices),texture:t.createImageTexture(e.texture,c.texture)})})),[i]),(0,o.useEffect)((0,h.sT)(null!==c.vertices,(()=>{let r=!0,a=parseInt("undefined"!=typeof performance?performance.now():(0).toString());const o=()=>{t.renderScene((t=>{let{gl:l,projectionMatrix:u,viewMatrix:h,modelMatrix:m}=t;if(!r)return;const f=parseInt("undefined"!=typeof performance?performance.now():(0).toString());f-a>100&&(a=f,p(f));const d=s.vt(),v=f/30%2160*Math.PI/180;s.Qr(d,m,v),s.eL(d,d,v/2),s.Z8(d,d,v/3);const x=s.vt();s.lw(x,h,d),s.lw(x,u,x),l.bindBuffer(l.ARRAY_BUFFER,c.vertices),l.vertexAttribPointer(i.vertex.attributeLocations.vertexPosition,3,l.FLOAT,!1,0,0),l.enableVertexAttribArray(i.vertex.attributeLocations.vertexPosition),l.bindBuffer(l.ARRAY_BUFFER,c.uvs),l.vertexAttribPointer(i.vertex.attributeLocations.vertexUv,2,l.FLOAT,!1,0,0),l.enableVertexAttribArray(i.vertex.attributeLocations.vertexUv),l.bindBuffer(l.ELEMENT_ARRAY_BUFFER,c.indices),l.useProgram(n),l.uniformMatrix4fv(i.vertex.uniformLocations.mvpMatrix,!1,x),l.uniform1f(i.fragment.uniformLocations.time,f),l.activeTexture(l.TEXTURE0),l.bindTexture(l.TEXTURE_2D,c.texture),l.uniform1i(i.fragment.uniformLocations.colorTextureSampler,0),l.drawElements(l.TRIANGLES,e.indices.length*e.indices[0].length,l.UNSIGNED_SHORT,0),requestAnimationFrame(o)}))};return requestAnimationFrame(o),()=>{r=!1}})),[c]),o.createElement("div",{className:"util text-center",style:{padding:"1rem"}},o.createElement("canvas",{width:"640",height:"480",ref:v},"Cannot run WebGL examples (not supported)"),o.createElement("pre",{className:"util text-left"},("\nCube:\n    Vertices:\n        Vertex 1: "+(0,h.NW)(e.vertices[0])+"\n        Vertex 2: "+(0,h.NW)(e.vertices[1])+"\n        Vertex 3: "+(0,h.NW)(e.vertices[2])+"\n        Vertex 4: "+(0,h.NW)(e.vertices[5])+"\n        Vertex 5: "+(0,h.NW)(e.vertices[30])+"\n        Vertex 6: "+(0,h.NW)(e.vertices[31])+"\n        Vertex 7: "+(0,h.NW)(e.vertices[32])+"\n        Vertex 8: "+(0,h.NW)(e.vertices[35])+"\n    Face UV:\n        Vertex 1: "+(0,h.nr)(T[0])+"\n        Vertex 2: "+(0,h.nr)(T[1])+"\n        Vertex 3: "+(0,h.nr)(T[2])+"\n        Vertex 4: "+(0,h.nr)(T[3])+"\n").trim()),o.createElement("pre",{className:"util text-left"},"Time: ",d))})),V=r(7570),U=r(2007),F=r(2269);var N=e=>{let{location:{pathname:t}}=e;return o.createElement(V.A,null,o.createElement(F.A,{pathname:t,title:"Shader Intermediates - Color Mapping",description:"A look into the how color textures are used to color objects in shaders.",keywords:["color","mapping","texturing","shader","intermediates"]}),o.createElement(i.A,null,o.createElement("h1",null,"Shader Intermediates - Color Mapping"),o.createElement("p",null,"So far we've passed direct color information of vertices to the fragment shader, which was then interpolated for each fragment and then set as the pixel color."),o.createElement("p",null,"As learnt in the"," ",o.createElement(n.Link,{to:"/basics/fragment-shader/"},"fragment shader basics"),", color information can only be mapped to the vertices of an object, with color values of parts of the object between the vertices being interpolated."),o.createElement("p",null,"However, as we learnt in the"," ",o.createElement(n.Link,{to:"/intermediate/mapping/"},"mapping")," chapter, we can use a texture to add much more detail to an object through the process of UV mapping."),o.createElement("p",null,"We can use the process of mapping to map colors of a fragment from the color data stored in a texture/color map. This process is called color mapping."),o.createElement("p",null,"Color mapping is also referred to as texturing due to the fact that textures only hold color data, and are primarily used to color fragments in an image."),o.createElement("p",null,"Let's look at an example of color mapping where an image is used as a texture to color the faces of a cube."),o.createElement(c.A,{type:"h2"},"An example - A cube"),o.createElement(b,null),o.createElement(c.A,{type:"h3"},"How it works"),o.createElement("p",null,"The following texture is used to color the each face of the rendered cube:"),o.createElement("div",{className:"image util text-center"},o.createElement(a.S,{src:"../../images/intermediates/texture.png",alt:"Cube Face Texture",style:{maxWidth:"65%"},__imageData:r(606)})),o.createElement("p",null,"The vertices of each face are mapped to the corners of the texture. You can look at the cube details below the rendered image to see the UV coordinates of the vertices of a single face."),o.createElement("p",null,o.createElement("em",null,"Note: For OpenGL/WebGL, the origin for UV coordinates is the lower-left corner of an image. For DirectX, the origin for UV coordinates is the upper-left corner of an image. When translating shader code between these languages, take care of the Y-axis values of the UV coordinates.")),o.createElement("p",null,"These UV coordinates are passed as part of the vertex data to the GPU. When these coordinates are passed to the fragment shader through the vertex shader, the GPU interpolates the UV coordinates of the fragments."),o.createElement("p",null,"For example, a fragment in the center of the face is equi-distant from all four vertices of the face. Since the vertices are mapped to the corners of the texture, the fragment will receive an interpolated UV coordinate at the center of the texture."),o.createElement("p",null,"Using these interpolated UV coordinates, the color of the texture at that point can be read by the fragment shader, which will represent the final color of that fragment, since the UV coordinate represents the location of the fragment within the texture."),o.createElement(l.A,{code:p.trim(),type:"Vertex"}),o.createElement(l.A,{code:v.trim(),type:"Fragment"}),o.createElement("p",null,"In the vertex shader code above, the UV coordinates of the vertex is provided through the ",o.createElement("code",null,"vertexUv")," attribute, which is then passed to the fragment shader through ",o.createElement("code",null,"uv"),", allowing the GPU to interpolate the UV coordinates for each fragment."),o.createElement("p",null,"In the fragment shader, the pixel color value of the texture at the given UV coordinates is retrieved through the 2D sampler"," ",o.createElement("code",null,"colorTextureSampler"),", which is then the final color assigned to the fragment."),o.createElement("p",null,o.createElement("code",null,"colorTextureSampler")," is defined as ",o.createElement("code",null,"sampler2D")," ","because the texture is a 2D image which is being sampled for color values at specific coordinates."),o.createElement(c.A,{type:"h2"},"Another example - A (mostly) pulsing cube"),o.createElement(L,null),o.createElement(c.A,{type:"h3"},"How it works"),o.createElement("p",null,"Similar to how the pulsing triangle was made in the last example of the"," ",o.createElement(n.Link,{to:"/basics/fragment-shader/"},"fragment shader basics"),", a"," ",o.createElement("code",null,"colorShift")," value is subtracted from the color values retrieved from the texture (except for alpha), and then set as the final color of the fragment."),o.createElement("p",null,"One unique change is the white edges of the cube, which do not pulse and always stay constant."),o.createElement(l.A,{code:A.trim(),type:"Fragment"}),o.createElement("p",null,"In the code, a new function ",o.createElement("code",null,"getColorShiftFactor")," accepts an RGB ",o.createElement("code",null,"color")," variable, and using a formula, decides whether the color shift should be factored by 0 or 1."),o.createElement("p",null,"If 0 is returned, the final color shift value is nullified, not affecting the value of the texture color when it is set to the final fragment color value."),o.createElement("p",null,"If 1 is returned, the final color shift value is in full effect, affecting the texture color value as it normally would when setting the final fragment color value."),o.createElement("p",null,"The color shift factor formula works as follows:"),o.createElement("ul",null,o.createElement("li",null,"Combine the values of the red, green, and blue components of the texture color."),o.createElement("li",null,"Subtract this value from 3.0"),o.createElement("li",null,"Ceil the difference at or above it (ex: it would change the number 2.1 to 3)."),o.createElement("li",null,"Clamp the resultant value so that it is within the range 0 - 1")),o.createElement("p",null,"When a color is white, it's RGB components would all be at their highest value, which is 1. As a result, their sum would be 3. When this sum is subtracted from the value 3, any color value that is not white would result in a difference greater than 0."),o.createElement("p",null,"This will result in the ceiling value of any color that is not white be least 1 or higher, which is then clamped to 1."),o.createElement("p",null,"As a result, this equation ensures that all texture color values that are white have a color shift factor of 0, and the rest have a value of 1."),o.createElement(c.A,{type:"h2"},"Additional Notes"),o.createElement("p",null,"If you're working with OpenGL/WebGL, there is one thing you will need to remember when working with textures."),o.createElement("p",null,"Typically when images are read, their starting coordinates are at the top-left of the image. This means that the origin coordinates"," ",o.createElement("code",null,"(0, 0, 0)")," represents the top-left most pixel of the image."),o.createElement("p",null,"However, in OpenGL/WebGL the starting coordinate is instead the bottom-left of the image. This means that if you try to load an image the same way in OpenGL as in DirectX, you will find that the image is flipped vertically when sampling and rendering it in your shader."),o.createElement("p",null,"As a result, you have two possible options:"),o.createElement("ul",null,o.createElement("li",null,"Flip the image vertically when loading it in OpenGL to keep things consistent in the shader."),o.createElement("li",null,"Invert the Y-axis of your UV coordinates when sampling from the image texture.")),o.createElement("p",null,"Since our tutorial uses WebGL, we need to use one of these options to prevent textures from appearing inverted. We've gone with the first option to keep the shader logic more consistent. If you're using OpenGL/WebGL, you'll need to keep this in mind as well."),o.createElement(c.A,{type:"h2"},"Summary"),o.createElement("ul",null,o.createElement("li",null,"Through the process of UV mapping, we can define the color of each fragment of an object through the use of a texture."),o.createElement("li",null,"Each vertex is assigned a UV coordinate on the texture, which is then interpolated by the GPU for each fragment."),o.createElement("li",null,"The fragment shader can then read the color value of the texture at the interpolated UV coordinate for the fragment to determine and set the final color of that fragment."))),o.createElement(U.A,{previous:"/intermediates/mapping/",next:"/intermediates/lighting/"}))}},6018:function(e,t,r){t.A=r.p+"static/texture-d46d879879755d42e588c10e2b6c3335.png"},606:function(e){e.exports=JSON.parse('{"layout":"constrained","backgroundColor":"#080808","images":{"fallback":{"src":"/static/78c94e1f8f2ed2661ab55399224256ed/acb7c/texture.png","srcSet":"/static/78c94e1f8f2ed2661ab55399224256ed/1c9ce/texture.png 64w,\\n/static/78c94e1f8f2ed2661ab55399224256ed/bf8e1/texture.png 128w,\\n/static/78c94e1f8f2ed2661ab55399224256ed/acb7c/texture.png 256w","sizes":"(min-width: 256px) 256px, 100vw"},"sources":[{"srcSet":"/static/78c94e1f8f2ed2661ab55399224256ed/8257c/texture.webp 64w,\\n/static/78c94e1f8f2ed2661ab55399224256ed/6766a/texture.webp 128w,\\n/static/78c94e1f8f2ed2661ab55399224256ed/22bfc/texture.webp 256w","type":"image/webp","sizes":"(min-width: 256px) 256px, 100vw"}]},"width":256,"height":256}')}}]);
//# sourceMappingURL=component---src-pages-intermediates-color-mapping-js-0252a1f0d4411481ffc7.js.map